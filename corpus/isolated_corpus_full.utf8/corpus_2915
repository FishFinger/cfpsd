From - Thu Dec 10 14:31:10 2009
X-Mozilla-Status: 0001
X-Mozilla-Status2: 00000000
Delivered-To: jpprost@gmail.com
Received: by 10.114.60.10 with SMTP id i10cs26649waa;
        Thu, 3 Apr 2008 03:47:50 -0700 (PDT)
Received: by 10.86.9.8 with SMTP id 8mr7028557fgi.70.1207219668659;
        Thu, 03 Apr 2008 03:47:48 -0700 (PDT)
Return-Path: <corpora-bounces@uib.no>
Received: from noralf.uib.no (noralf.uib.no [129.177.30.12])
        by mx.google.com with ESMTP id 12si1907892fgg.6.2008.04.03.03.47.40;
        Thu, 03 Apr 2008 03:47:48 -0700 (PDT)
Received-SPF: pass (google.com: domain of corpora-bounces@uib.no designates 129.177.30.12 as permitted sender) client-ip=129.177.30.12;
Authentication-Results: mx.google.com; spf=pass (google.com: domain of corpora-bounces@uib.no designates 129.177.30.12 as permitted sender) smtp.mail=corpora-bounces@uib.no
Received: from localhost (noralf.uib.no) [127.0.0.1] 
	by noralf.uib.no  with esmtp  (Exim 4.34)
	id 1JhMnn-0004o0-Bv; Thu, 03 Apr 2008 12:36:15 +0200
Received: from rolf.uib.no [129.177.30.19] 
	by noralf.uib.no for corpora@lists.uib.no with esmtp  (Exim 4.34)
	id 1JhMnf-0004nU-OG; Thu, 03 Apr 2008 12:36:07 +0200
Received: from hydra.rus.uni-stuttgart.de [129.69.1.55] 
	by rolf.uib.no for corpora@uib.no with esmtp  (Exim 4.34)
	id 1JhMnc-00022X-Dp; Thu, 03 Apr 2008 12:36:08 +0200
Received: from localhost (localhost [127.0.0.1])
	by hydra.rus.uni-stuttgart.de (Postfix) with ESMTP id 0364B9BABA;
	Thu,  3 Apr 2008 12:36:01 +0200 (CEST)
X-Virus-Scanned: by amavisd-new at hydra.rus.uni-stuttgart.de
X-Spam-Flag: NO
X-Spam-Score: -4.399
X-Spam-Level: 
X-Spam-Status: No, score=-4.399 tagged_above=-999 required=5
	tests=[ALL_TRUSTED=-1.8, BAYES_00=-2.599]
Received: from hydra.rus.uni-stuttgart.de ([127.0.0.1])
	by localhost (hydra.rus.uni-stuttgart.de [127.0.0.1]) (amavisd-new,
	port 10024)
	with LMTP id RG6KyPO8KNp2; Thu,  3 Apr 2008 12:35:45 +0200 (CEST)
Received: from ssiw.local (vpn-v-026.campus.uni-stuttgart.de [129.69.196.26])
	by hydra.rus.uni-stuttgart.de (Postfix) with ESMTP id 892759B1AD;
	Thu,  3 Apr 2008 12:35:44 +0200 (CEST)
Message-ID: <47F4B2C5.40302@ims.uni-stuttgart.de>
Date: Thu, 03 Apr 2008 12:34:45 +0200
From: Sabine Schulte im Walde <schulte@ims.uni-stuttgart.de>
Organization: SSIW
User-Agent: Thunderbird 2.0.0.12 (Macintosh/20080213)
MIME-Version: 1.0
To: Corpora List <corpora@uib.no>
X-checked-clean: by exiscan on rolf
X-Scanner: 2a36a776f8a0e382fe0fd704c533a989 http://tjinfo.uib.no/virus.html
X-UiB-SpamFlag: NO UIB: 0.0 hits, 8.0 required
X-UiB-SpamReport: spamassassin found;
   0.1 Received: contains a forged HELO
Subject: [Corpora-List] 2nd CfP: Coling 2008 workshop on human judgements in
 Computational Linguistics
X-BeenThere: corpora@uib.no
X-Mailman-Version: 2.1.9
Precedence: list
Reply-To: schulte@ims.uni-stuttgart.de
List-Id: <corpora.uib.no>
List-Unsubscribe: <http://mailman.uib.no/listinfo/corpora>,
	<mailto:corpora-request@uib.no?subject=unsubscribe>
List-Archive: <http://www.uib.no/mailman/public/corpora>
List-Post: <mailto:corpora@uib.no>
List-Help: <mailto:corpora-request@uib.no?subject=help>
List-Subscribe: <http://mailman.uib.no/listinfo/corpora>,
	<mailto:corpora-request@uib.no?subject=subscribe>
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
Sender: corpora-bounces@uib.no
Errors-To: corpora-bounces@uib.no

Coling 2008 workshop on human judgements in Computational Linguistics

                   *** 2nd Call for Papers ***

                          Manchester, UK
                          23 August 2008

               http://workshops.inf.ed.ac.uk/hjcl/
 =

               Deadline for submission: 5 May 2008

----------------------------------------------------------------------

Workshop Description

Human judgements play a key role in the development and the assessment
of linguistic resources and methods in Computational Linguistics. They
are commonly used in the creation of lexical resources and corpus
annotation, and also in the evaluation of automatic approaches to
linguistic tasks. Furthermore, systematically collected human
judgements provide clues for research on linguistic issues that
underlie the judgement task, providing insights complementary to
introspective analysis or evidence gathered from corpora.

We invite papers about experiments that collect human judgements for
Computational Linguistic purposes, with a particular focus on
linguistic tasks that are controversial from a theoretical point of
view (e.g., some coding tasks having to do with semantics or
pragmatics). Such experimental tasks are usually difficult to design
and interpret, and they typically result in mediocre inter-rater
reliability. We seek both broad methodological papers discussing these
issues, and specific case studies.

Topics of interest include, but are not limited to:

* Experimental design:

  - Which types of experiments support the collection of human
    judgements? Can any general guidelines be defined? Is there a
    preference between lab-based experiments and web-based
    experiments?
  - Which experimental methodologies support controversial tasks? For
    instance, does underspecification help? What is the role of
    ambiguity and polysemy in these tasks?
  - What is the appropriate level of granularity for the category
    labels?
  - What kind of participants should be used (e.g., expert
    vs. non-expert), how is it affected by the type of experiment, and
    how should the experiment design be varied according to this
    issue?
  - How much and which kind of information (examples, context, etc.)
    should be provided to the experiment participants? When does
    information turn into a bias?
  - Is it possible to design experiments that are useful for both
    computational linguistics and psycholinguistics? What do the two
    research areas have in common? What are the differences?

* Analysis and interpretation of experimental data:

  - How important is inter-annotator agreement in human judgement
    collection experiments? How is it best measured for complex tasks?
  - What other quantitative tools are useful for analysing human
    judgement collection experiments?
  - What qualitative methods are useful for analysing human judgement
    collection experiments? Which questions should be asked? Is it
    possible to formulate general guidelines?
  - How is the analysis similar to psycholinguistic analysis? How is
    it different?
  - How do results from all of the methods above affect the
    development of annotation instructions and procedures?

* Application of experiment insights:

  - How do the experimental data fit into the general
    resource-creating process?
  - How to modify the set of labels and the criteria or guidelines for
    the annotation task according to the experimental results? How to
    avoid circularity in this process?
  - How can the data be used to refine or modify existing theoretical
    proposals?
  - More generally, under what conditions can the obtained judgements
    be applied to research questions?


Organisers

Ron Artstein, Institute for Creative Technologies, University of =

Southern California
Gemma Boleda, Universitat Polit=E8cnica de Catalunya
Frank Keller, University of Edinburgh
Sabine Schulte im Walde, Universit=E4t Stuttgart


Keynote Speaker

Martha Palmer, University of Colorado


Programme Committee

Toni Badia, Universitat Pompeu Fabra
Marco Baroni, University of Trento
Beata Beigman Klebanov, Northwestern University
Andr=E9 Blessing, Universit=E4t Stuttgart
Chris Brew, Ohio State University
Kevin Cohen, University of Colorado Health Sciences Center
Barbara Di Eugenio, University of Illinois at Chicago
Katrin Erk, University of Texas at Austin
Stefan Evert, University of Osnabr=FCck
Afsaneh Fazly, University of Toronto
Alex Fraser, Universit=E4t Stuttgart
Jesus Gimenez, Universitat Polit=E8cnica de Catalunya
Roxana Girju, University of Illinois at Urbana-Champaign
Ed Hovy, University of Southern California
Nancy Ide, Vassar College
Adam Kilgarriff, University of Brighton
Alexander Koller, University of Edinburgh
Anna Korhonen, University of Cambridge
Mirella Lapata, University of Edinburgh
Diana McCarthy, University of Sussex
Alissa Melinger, University of Dundee
Paola Merlo, University of Geneva
Sebastian Pad=F3, Stanford University
Martha Palmer, University of Colorado
Rebecca Passonneau, Columbia University
Massimo Poesio, University of Trento
Sameer Pradhan, BBN Technologies
Horacio Rodriguez, Universitat Polit=E8cnica de Catalunya
Bettina Schrader, Universit=E4t Potsdam
Suzanne Stevenson, University of Toronto


Submission

Deadline for the receipt of papers is 5 May 2008, 23:59 UTC. Submit
your paper via the submissions web page:
     http://workshops.inf.ed.ac.uk/hjcl/submission.html

Submissions should be anonymous. Please submit only PDF files, 8 pages
long (including data, tables, figures, and references). We recommend
to follow the Coling 2008 style guidelines. Include a one-paragraph
abstract of the entire work (about 200 words). Accepted papers will
appear in an on-line proceedings volume.


Important Dates

Paper submission deadline: 5 May 2008
Notification of acceptance: 10 June 2008
Camera-ready copy due: 1 July 2008
Workshop date: 23 August 2008


_______________________________________________
Corpora mailing list
Corpora@uib.no
http://mailman.uib.no/listinfo/corpora
