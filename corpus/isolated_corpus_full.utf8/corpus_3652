From - Thu Dec 10 14:33:43 2009
X-Mozilla-Status: 0001
X-Mozilla-Status2: 00000000
Delivered-To: jpprost@gmail.com
Received: by 10.102.247.5 with SMTP id u5cs687101muh;
        Mon, 13 Oct 2008 09:42:16 -0700 (PDT)
Received: by 10.67.116.16 with SMTP id t16mr3374100ugm.62.1223916136146;
        Mon, 13 Oct 2008 09:42:16 -0700 (PDT)
Return-Path: <corpora-bounces@uib.no>
Received: from noralf.uib.no (noralf.uib.no [129.177.30.12])
        by mx.google.com with ESMTP id a1si6035484ugf.37.2008.10.13.09.42.07;
        Mon, 13 Oct 2008 09:42:16 -0700 (PDT)
Received-SPF: pass (google.com: domain of corpora-bounces@uib.no designates 129.177.30.12 as permitted sender) client-ip=129.177.30.12;
Authentication-Results: mx.google.com; spf=pass (google.com: domain of corpora-bounces@uib.no designates 129.177.30.12 as permitted sender) smtp.mail=corpora-bounces@uib.no
Received: from localhost (noralf.uib.no) [127.0.0.1] 
	by noralf.uib.no  with esmtp  (Exim 4.69)
	id 1KpQKl-0004uk-0e; Mon, 13 Oct 2008 18:31:51 +0200
Received: from rolf.uib.no [129.177.30.19] 
	by noralf.uib.no for corpora@lists.uib.no with esmtp  (Exim 4.69)
	id 1KpQKe-0004u0-BF; Mon, 13 Oct 2008 18:31:44 +0200
Received: from mxout2.cac.washington.edu [140.142.33.4] 
	by rolf.uib.no for corpora@uib.no with esmtps (TLSv1:AES256-SHA:256)
	(Exim 4.69) id 1KpQKg-0002Lw-Q4; Mon, 13 Oct 2008 18:31:48 +0200
Received: from smtp.washington.edu (smtp.washington.edu [140.142.32.139])
	by mxout2.cac.washington.edu (8.13.7+UW06.06/8.13.7+UW07.09) with ESMTP
	id m9DGVdQJ003885
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=OK)
	for <corpora@uib.no>; Mon, 13 Oct 2008 09:31:39 -0700
X-Auth-Received: from [192.168.1.2] (c-76-121-4-216.hsd1.wa.comcast.net
	[76.121.4.216]) (authenticated authid=kevinduh)
	by smtp.washington.edu (8.13.7+UW06.06/8.13.7+UW07.09) with ESMTP id
	m9DGVcrv025994
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NOT)
	for <corpora@uib.no>; Mon, 13 Oct 2008 09:31:39 -0700
Message-ID: <48F377EA.5090803@u.washington.edu>
Date: Mon, 13 Oct 2008 09:31:38 -0700
From: Kevin Duh <kevinduh@u.washington.edu>
User-Agent: Thunderbird 2.0.0.17 (Windows/20080914)
MIME-Version: 1.0
To: corpora@uib.no
X-PMX-Version: 5.4.3.345767, Antispam-Engine: 2.6.0.325393,
	Antispam-Data: 2008.10.13.161310
X-Uwash-Spam: Gauge=IIIIIII, Probability=7%, Report='BODY_SIZE_6000_6999 0,
	ECARD_KNOWN_DOMAINS 0, __CP_URI_IN_BODY 0, __CT 0, __CTE 0,
	__CT_TEXT_PLAIN 0, __FRAUD_419_BODY_WEBMAIL 0,
	__FRAUD_419_WEBMAIL 0, __HAS_MSGID 0, __LINES_OF_YELLING 0,
	__MIME_TEXT_ONLY 0, __MIME_VERSION 0, __SANE_MSGID 0,
	__USER_AGENT 0'
X-checked-clean: by exiscan on rolf
X-Scanner: 03f2907067fd531e85b26b40b8503abe http://tjinfo.uib.no/virus.html
X-UiB-SpamFlag: NO UIB: -14.3 hits, 8.0 required
X-UiB-SpamReport: spamassassin found; -15 From is listed in 'whitelist_SA'
	0.7 RAW: Contains a line >= 199 long
Subject: [Corpora-List] CFP: Workshop on Semi-supervised Learning for NLP at
	NAACL 2009
X-BeenThere: corpora@uib.no
X-Mailman-Version: 2.1.9
Precedence: list
List-Id: <corpora.uib.no>
List-Unsubscribe: <http://mailman.uib.no/listinfo/corpora>,
	<mailto:corpora-request@uib.no?subject=unsubscribe>
List-Archive: <http://www.uib.no/mailman/public/corpora>
List-Post: <mailto:corpora@uib.no>
List-Help: <mailto:corpora-request@uib.no?subject=help>
List-Subscribe: <http://mailman.uib.no/listinfo/corpora>,
	<mailto:corpora-request@uib.no?subject=subscribe>
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
Sender: corpora-bounces@uib.no
Errors-To: corpora-bounces@uib.no

=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
NAACL HLT 2009 Workshop on
Semi-supervised Learning for Natural Language Processing

June 4 or 5, 2009, Boulder, Colorado, USA
http://sites.google.com/site/sslnlp/

Call for Papers
(Submission deadline: March 6, 2009)
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D

Machine learning, be it supervised or unsupervised, has become an =

indispensable tool for natural language processing (NLP) researchers. =

Highly developed supervised training techniques have led to =

state-of-the-art performance for many NLP tasks and provide foundations =

for deployable NLP systems. Similarly, unsupervised methods, such as =

those based on EM training, have also been influential, with =

applications ranging from grammar induction to bilingual word alignment =

for machine translation.

Unfortunately, given the limited availability of annotated data, and the =

non-trivial cost of obtaining additional annotated data, progress on =

supervised learning often yields diminishing returns. Unsupervised =

learning, on the other hand, is not bound by the same data resource =

limits. However, unsupervised learning is significantly harder than =

supervised learning and, although intriguing, has not been able to =

produce consistently successful results for complex structured =

prediction problems characteristic of NLP.

It is becoming increasingly important to leverage both types of data =

resources, labeled and unlabeled, to achieve the best performance in =

challenging NLP problems. Consequently, interest in semi-supervised =

learning has grown in the NLP community in recent years. Yet, although =

several papers have demonstrated promising results with semi-supervised =

learning for problems such as tagging and parsing, we suspect that good =

results might not be easy to achieve across the board. Many =

semi-supervised learning methods (e.g. transductive SVM, graph-based =

methods) have been originally developed for binary classification =

problems. NLP problems often pose new challenges to these techniques, =

involving more complex structure that can violate many of the underlying =

assumptions.

We believe there is a need to take a step back and investigate why and =

how auxiliary unlabeled data can truly improve training for NLP tasks.

In particular, many open questions remain:

 1. Problem Structure: What are the different classes of NLP problem =

structures (e.g. sequences, trees, N-best lists) and what algorithms are =

best suited for each class? For instance, can graph-based algorithms be =

successfully applied to sequence-to-sequence problems like machine =

translation, or are self-training and feature-based methods the only =

reasonable choices for these problems?

 2. Background Knowledge: What kinds of NLP-specific background =

knowledge can we exploit to aid semi-supervised learning? Recent =

learning paradigms such as constraint-driven learning and prototype =

learning take advantage of our domain knowledge about particular NLP =

tasks; they represent a move away from purely data-agnostic methods and =

are good examples of how linguistic intuition can drive algorithm =

development.

 3. Scalability: NLP data-sets are often large. What are the scalability =

challenges and solutions for applying existing semi-supervised learning =

algorithms to NLP data?

 4. Evaluation and Negative Results: What can we learn from negative =

results? Can we make an educated guess as to when semi-supervised =

learning might outperform supervised or unsupervised learning based on =

what we know about the NLP problem?

 5. To Use or Not To Use: Should semi-supervised learning only be =

employed in low-resource languages/tasks (i.e. little labeled data, much =

unlabeled data), or should we expect gains even in high-resource =

scenarios (i.e. expecting semi-supervised learning to improve on a =

supervised system that is already more than 95% accurate)?

This workshop aims to bring together researchers dedicated to making =

semi-supervised learning work for NLP problems. Our goal is to help =

build a community of researchers and foster deep discussions about =

insights, speculations, and results (both positive and negative) that =

may otherwise not appear in a technical paper at a major conference. We =

welcome submissions that address any of the above questions or other =

relevant issues, and especially encourage authors to provide a deep =

analysis of data and results. Papers will be limited to 8 pages and will =

be selected based on quality and relevance to workshop goals.

IMPORTANT DATES:
March 6, 2009: Submission deadline
March 30, 2009: Notification of acceptance
April 12, 2009: Camera-ready copies due
June 4 or 5, 2009: Workshop held in conjunction with NAACL HLT (exact =

date to be announced)

PROGRAM COMMITTEE:
Steven Abney (University of Michigan, USA)
Yasemin Altun (Max Planck Institute for Biological Cybernetics, Germany)
Tim Baldwin (University of Melbourne, Australia)
Shane Bergsma (University of Alberta, Canada)
Antal van den Bosch (Tilburg University, The Netherlands)
John Blitzer (UC Berkeley, USA)
Ming-Wei Chang (UIUC, USA)
Walter Daelemans (University of Antwerp, Belgium)
Hal Daume III (University of Utah, USA)
Kevin Gimpel (Carnegie Mellon University, USA)
Andrew Goldberg (University of Wisconsin, USA)
Liang Huang (Google Research, USA)
Rie Johnson [formerly, Ando] (RJ Research Consulting)
Katrin Kirchhoff (University of Washington, USA)
Percy Liang (UC Berkeley, USA)
Gary Geunbae Lee (POSTECH, Korea)
Gina-Anne Levow (University of Chicago, USA)
Gideon Mann (Google, USA)
David McClotsky (Brown University, USA)
Ray Mooney (UT Austin, USA)
Hwee Tou Ng (National University of Singapore, Singapore)
Vincent Ng (UT Dallas, USA)
Miles Osborne (University of Edinburgh, UK)
Mari Ostendorf (University of Washington, USA)
Chris Pinchak (University of Alberta, Canada)
Dragomir Radev (University of Michigan, USA)
Dan Roth (UIUC, USA)
Anoop Sarkar (Simon Fraser University, Canada)
Dale Schuurmans (University of Alberta, Canada)
Akira Shimazu (JAIST, Japan)
Jun Suzuki (NTT, Japan)
Yee Whye Teh (University College London, UK)
Kristina Toutanova (Microsoft Research, USA)
Jason Weston (NEC, USA)
Tong Zhang (Rutgers University, USA)
Ming Zhou (Microsoft Research Asia, China)
Xiaojin (Jerry) Zhu (University of Wisconsin, USA)

ORGANIZERS AND CONTACT:
- Qin Wang (Yahoo!)
- Kevin Duh (University of Washington)
- Dekang Lin (Google Research)
Email: ssl.nlp2009@gmail.com
Website: http://sites.google.com/site/sslnlp/

_______________________________________________
Corpora mailing list
Corpora@uib.no
http://mailman.uib.no/listinfo/corpora
